HPC Final

1)Parallel BFS DFS using OpenMP

-----CODE---------------------------------------------------------------------
#include <iostream>
#include <vector>
#include <queue>
#include <stack>
#include <omp.h>

using namespace std;

// Graph class representing an undirected graph using adjacency list representation
class Graph {
private:
    int numVertices;          // Number of vertices
    vector<vector<int>> adj;  // Adjacency list

public:
    Graph(int vertices) : numVertices(vertices), adj(vertices) {}

    // Add an edge between two vertices
    void addEdge(int src, int dest) {
        adj[src].push_back(dest);
        adj[dest].push_back(src);
    }

    // View the graph
    void viewGraph() {
        cout << "Graph:\n";
        for (int i = 0; i < numVertices; i++) {
            cout << "Vertex " << i << " -> ";
            for (int neighbor : adj[i]) {
                cout << neighbor << " ";
            }
            cout << endl;
        }
    }

    // Perform Breadth First Search (BFS) in parallel
    void bfs(int startVertex) {
        vector<bool> visited(numVertices, false);
        queue<int> q;

        // Mark the start vertex as visited and enqueue it
        visited[startVertex] = true;
        q.push(startVertex);

        while (!q.empty()) {
            int currentVertex = q.front();
            q.pop();
            cout << currentVertex << " ";

            // Enqueue all adjacent unvisited vertices
            #pragma omp parallel for
            for (int neighbor : adj[currentVertex]) {
                if (!visited[neighbor]) {
                    visited[neighbor] = true;
                    q.push(neighbor);
                }
            }
        }
    }

    // Perform Depth First Search (DFS) in parallel
    void dfs(int startVertex) {
        vector<bool> visited(numVertices, false);
        stack<int> s;

        // Mark the start vertex as visited and push it onto the stack
        visited[startVertex] = true;
        s.push(startVertex);

        while (!s.empty()) {
            int currentVertex = s.top();
            s.pop();
            cout << currentVertex << " ";

            // Push all adjacent unvisited vertices onto the stack
            #pragma omp parallel for
            for (int neighbor : adj[currentVertex]) {
                if (!visited[neighbor]) {
                    visited[neighbor] = true;
                    s.push(neighbor);
                }
            }
        }
    }
};

int main() {
    int numVertices;
    cout << "Enter the number of vertices in the graph: ";
    cin >> numVertices;

    // Create a graph with the specified number of vertices
    Graph graph(numVertices);

    int numEdges;
    cout << "Enter the number of edges in the graph: ";
    cin >> numEdges;

    cout << "Enter the edges (source destination):\n";
    for (int i = 0; i < numEdges; i++) {
        int src, dest;
        cin >> src >> dest;
        graph.addEdge(src, dest);
    }

    // View the graph
    graph.viewGraph();

    int startVertex;
    cout << "Enter the starting vertex for BFS and DFS: ";
    cin >> startVertex;

    cout << "Breadth First Search (BFS): ";
    graph.bfs(startVertex);
    cout << endl;

    cout << "Depth First Search (DFS): ";
    graph.dfs(startVertex);
    cout << endl;

    return 0;
}

-----------------EXPLANATION-------------------------------------------------------------------------
Certainly! Let's delve deeper into each component of the code:

### Libraries Included:
- `iostream`: Standard input-output stream library for basic input and output operations.
- `vector`: Standard library for dynamically sized arrays, used here to represent the adjacency list.
- `queue`: Standard library for queues, utilized in BFS traversal.
- `stack`: Standard library for stacks, utilized in DFS traversal.
- `omp.h`: OpenMP library for parallel programming, used for parallelizing BFS and DFS traversals.

### `Graph` Class Definition:
- **Private Members:**
  - `numVertices`: An integer representing the number of vertices in the graph.
  - `adj`: A vector of vectors representing the adjacency list. Each element of the outer vector corresponds to a vertex, and its corresponding inner vector contains the indices of vertices adjacent to it.
- **Public Methods:**
  - `Graph(int vertices)`: Constructor to initialize the graph with a given number of vertices.
  - `addEdge(int src, int dest)`: Method to add an undirected edge between two vertices `src` and `dest`.
  - `viewGraph()`: Method to print the adjacency list representation of the graph.
  - `bfs(int startVertex)`: Method to perform Breadth First Search (BFS) traversal starting from a specified vertex.
  - `dfs(int startVertex)`: Method to perform Depth First Search (DFS) traversal starting from a specified vertex.

### `main()` Function:
- **Input Handling:**
  - Prompts the user to enter the number of vertices (`numVertices`) and edges (`numEdges`) in the graph.
  - Reads user input for the number of vertices and edges.
  - Creates a `Graph` object `graph` with the specified number of vertices.
  - Prompts the user to enter each edge and adds them to the graph using the `addEdge()` method.
- **Graph Visualization:**
  - Prints the adjacency list representation of the graph using `viewGraph()`.
- **Traversal:**
  - Prompts the user to enter a starting vertex (`startVertex`) for BFS and DFS traversal.
  - Performs BFS traversal starting from the specified starting vertex using the `bfs()` method and prints the result.
  - Performs DFS traversal starting from the specified starting vertex using the `dfs()` method and prints the result.

### `addEdge(int src, int dest)` Method:
- Adds an undirected edge between two vertices by updating their adjacency lists.
- For an edge between vertices `src` and `dest`, it adds `dest` to the adjacency list of `src` and vice versa.

### `viewGraph()` Method:
- Prints the adjacency list representation of the graph.
- Iterates through each vertex and its adjacent vertices, printing them on separate lines.

### `bfs(int startVertex)` Method:
- Performs Breadth First Search (BFS) traversal starting from the specified `startVertex`.
- Uses a queue (`q`) to keep track of vertices to visit next.
- Uses a boolean vector `visited` to mark visited vertices.
- Enqueues the `startVertex`, marks it as visited, and then iteratively dequeues vertices and enqueues their unvisited neighbors until the queue is empty.

### `dfs(int startVertex)` Method:
- Performs Depth First Search (DFS) traversal starting from the specified `startVertex`.
- Uses a stack (`s`) to keep track of vertices to visit next.
- Uses a boolean vector `visited` to mark visited vertices.
- Pushes the `startVertex` onto the stack, marks it as visited, and then iteratively pops vertices and pushes their unvisited neighbors until the stack is empty.

### Parallelization:
- Both `bfs()` and `dfs()` methods use `#pragma omp parallel for` to parallelize the loop that processes adjacent vertices.
- This directive allows the loop iterations to execute in parallel, potentially speeding up the traversal process.

Overall, the code provides functionality to create, visualize, and traverse an undirected graph using both BFS and DFS algorithms. Additionally, it leverages parallelization techniques to potentially improve the performance of traversals.

------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------
2)Bubble/Merge Parallel vs Sequential Performance


#include <iostream>
#include <ctime>
#include <cstdlib>
#include <omp.h>

using namespace std;

void bubbleSort(int arr[], int n)
{
    for (int i = 0; i < n - 1; ++i)
    {
        for (int j = 0; j < n - i - 1; ++j)
        {
            if (arr[j] > arr[j + 1])
            {
                swap(arr[j], arr[j + 1]);
            }
        }
    }
}

void merge(int arr[], int l, int m, int r)
{
    int i, j, k;
    int n1 = m - l + 1;
    int n2 = r - m;

    int *L = new int[n1];
    int *R = new int[n2];

    for (i = 0; i < n1; ++i)
    {
        L[i] = arr[l + i];
    }
    for (j = 0; j < n2; ++j)
    {
        R[j] = arr[m + 1 + j];
    }

    i = 0;
    j = 0;
    k = l;

    while (i < n1 && j < n2)
    {
        if (L[i] <= R[j])
        {
            arr[k] = L[i];
            ++i;
        }
        else
        {
            arr[k] = R[j];
            ++j;
        }
        ++k;
    }

    while (i < n1)
    {
        arr[k] = L[i];
        ++i;
        ++k;
    }

    while (j < n2)
    {
        arr[k] = R[j];
        ++j;
        ++k;
    }

    delete[] L;
    delete[] R;
}

void mergeSort(int arr[], int l, int r)
{
    if (l < r)
    {
        int m = l + (r - l) / 2;
        #pragma omp parallel sections
        {
            #pragma omp section
            {
                mergeSort(arr, l, m);
            }
            #pragma omp section
            {
                mergeSort(arr, m + 1, r);
            }
        }

        merge(arr, l, m, r);
    }
}

void printArray(int arr[], int size)
{
    for (int i = 0; i < size; ++i)
    {
        cout << arr[i] << " ";
    }
    cout << endl;
}

int main()
{
    int n;
    cout << "Enter the size of the array: ";
    cin >> n;

    int *arr = new int[n];
    srand(time(0));
    for (int i = 0; i < n; ++i)
    {
        arr[i] = rand() % 100;
    }

    cout << "Original array: ";
    printArray(arr, n);

    // Sequential Bubble Sort
    clock_t start = clock();
    bubbleSort(arr, n);
    clock_t end = clock();

    cout << "Sequential Bubble Sorted array: ";
    printArray(arr, n);

    double sequentialBubbleTime = double(end - start) / CLOCKS_PER_SEC;

    // Parallel Bubble Sort
    start = clock();
    #pragma omp parallel
    {
        bubbleSort(arr, n);
    }
    end = clock();

    cout << "Parallel Bubble Sorted array: ";
    printArray(arr, n);

    double parallelBubbleTime = double(end - start) / CLOCKS_PER_SEC;

    // Merge Sort
    start = clock();
    mergeSort(arr, 0, n - 1);
    end = clock();

    cout << "Sequential Merge Sorted array: ";
    printArray(arr, n);

    double sequentialMergeTime = double(end - start) / CLOCKS_PER_SEC;

    // Parallel Merge Sort
    start = clock();
    #pragma omp parallel
    {
        #pragma omp single
        {
            mergeSort(arr, 0, n - 1);
        }
    }
    end = clock();

    cout << "Parallel Merge Sorted array: ";
    printArray(arr, n);

    double parallelMergeTime = double(end - start) / CLOCKS_PER_SEC;

    // Performance measurement
    cout << "Sequential Bubble Sort Time: " << sequentialBubbleTime << " seconds" << endl;
    cout << "Parallel Bubble Sort Time: " << parallelBubbleTime << " seconds" << endl;
    cout << "Sequential Merge Sort Time: " << sequentialMergeTime << " seconds" << endl;
    cout << "Parallel Merge Sort Time: " << parallelMergeTime << " seconds" << endl;

    delete[] arr;

    return 0;
}

------------EXPLANATION-------------------------------------------------------------------------
Let's break down the code step by step:

1. **Header Files**:
   - The code includes necessary header files:
     - `<iostream>`: for input/output operations.
     - `<ctime>`: for time-related functions.
     - `<cstdlib>`: for functions such as `rand()` and `srand()`.
     - `<omp.h>`: for OpenMP parallel programming functionalities.

2. **Function Declarations**:
   - Two sorting algorithms are defined:
     - `bubbleSort`: Implements the bubble sort algorithm.
     - `mergeSort`: Implements the merge sort algorithm.
   - Other utility functions are also defined:
     - `merge`: Merges two subarrays in the merge sort algorithm.
     - `printArray`: Prints the elements of an array.

3. **Main Function**:
   - Asks the user to enter the size of the array (`n`).
   - Dynamically allocates memory for an array of size `n`.
   - Generates random integers between 0 and 99 and assigns them to the array elements.

4. **Sorting Operations**:
   - Performs sequential bubble sort to sort the array.
     - Measures the time taken for the sequential bubble sort.
   - Performs parallel bubble sort using OpenMP directives.
     - Measures the time taken for the parallel bubble sort.
   - Performs sequential merge sort to sort the array.
     - Measures the time taken for the sequential merge sort.
   - Performs parallel merge sort using OpenMP directives.
     - Measures the time taken for the parallel merge sort.

5. **Performance Measurement**:
   - Prints the sorted arrays and the time taken for each sorting operation (both sequential and parallel).

6. **Memory Management**:
   - Deallocates the dynamically allocated memory for the array using `delete[]` to prevent memory leaks.

7. **Explanation**:
   - The code compares the performance of sequential and parallel implementations of bubble sort and merge sort algorithms.
   - It aims to demonstrate the potential speedup achieved by parallelizing sorting algorithms using OpenMP.

In summary, the code dynamically generates an array of random integers, sorts it using both sequential and parallel versions of bubble sort and merge sort algorithms, and measures the time taken for each operation to compare their performance. It leverages OpenMP for parallelization, which allows multiple threads to work on sorting the array simultaneously, potentially reducing the overall execution time.
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------


3).Implement Min, Max, Sum and Average operations using Parallel Reduction.


#include <iostream>
#include <omp.h>
#include <climits>

using namespace std;

void min_reduction(int arr[], int n) {
    int min_value = INT_MAX;
    #pragma omp parallel for reduction(min: min_value)
    for (int i = 0; i < n; i++) {
        if (arr[i] < min_value) {
            min_value = arr[i];
        }
    }
    cout << "Minimum value: " << min_value << endl;
}

void max_reduction(int arr[], int n) {
    int max_value = INT_MIN;
    #pragma omp parallel for reduction(max: max_value)
    for (int i = 0; i < n; i++) {
        if (arr[i] > max_value) {
            max_value = arr[i];
        }
    }
    cout << "Maximum value: " << max_value << endl;
}

void sum_reduction(int arr[], int n) {
    int sum = 0;
    #pragma omp parallel for reduction(+: sum)
    for (int i = 0; i < n; i++) {
        sum += arr[i];
    }
    cout << "Sum: " << sum << endl;
}

void average_reduction(int arr[], int n) {
    int sum = 0;
    #pragma omp parallel for reduction(+: sum)
    for (int i = 0; i < n; i++) {
        sum += arr[i];
    }
    cout << "Average: " << (double)sum / n << endl;
}

int main() {
    int *arr, n;
    cout << "\nEnter total number of elements: ";
    cin >> n;
    arr = new int[n];
    cout << "\nEnter elements: ";
    for(int i = 0; i < n; i++) {
        cin >> arr[i];
    }
    min_reduction(arr, n);
    max_reduction(arr, n);
    sum_reduction(arr, n);
    average_reduction(arr, n);
    delete[] arr;
    return 0;
}

-----------------EXPLANATION---------------------------

Header Files:
The code includes necessary header files like <iostream> for input/output, <omp.h> for OpenMP functionalities, and <climits> for using constants like INT_MAX and INT_MIN.
Function Declarations:
The code declares several functions:
min_reduction: Finds the minimum value in an array.
max_reduction: Finds the maximum value in an array.
sum_reduction: Computes the sum of all elements in an array.
average_reduction: Computes the average value of elements in an array.

Function Definitions:
Each function is defined to perform a specific task using OpenMP parallelization.
min_reduction and max_reduction use OpenMP's reduction clause with min and max operators to find the minimum and maximum values, respectively.
sum_reduction and average_reduction use OpenMP's reduction clause with + operator to compute the sum of all elements.

Main Function:
The main function is where the program starts executing.
It prompts the user to enter the total number of elements and then the elements themselves.
It dynamically allocates memory for the array based on the user input and initializes the array with the entered elements.

Function Calls:
The main function then calls each of the four reduction functions:
min_reduction to find the minimum value in the array.
max_reduction to find the maximum value in the array.
sum_reduction to compute the sum of all elements in the array.
average_reduction to compute the average value of elements in the array.

Parallelization:
OpenMP directives are used to parallelize the loops in the reduction functions, allowing multiple threads to work on different parts of the array simultaneously.
The reduction clause ensures that each thread maintains its own private copy of the reduction variable (e.g., min_value, max_value, sum) and combines them at the end using the specified reduction operation (min, max, +).

Output:
Each reduction function prints its result (minimum value, maximum value, sum, or average) to the console.
Memory Management:
Memory allocated for the array is deallocated at the end of the main function using delete[] to avoid memory leaks.

In summary, the code demonstrates how to use OpenMP directives for parallel reduction operations to efficiently find the minimum, maximum, sum, and average values of elements in an array. It leverages parallelism to distribute the workload among multiple threads, thereby speeding up the computation for large datasets.
